{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I can use pd.read_csv(\"passwords1.txt\", header=None, delim_whitespace=True) becvause it will skip some lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of passwords in passwords1.txt 100000000\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "with open(\"passwords1.txt\") as infile:\n",
    "    for line in infile:\n",
    "        i = i+1\n",
    "print('Number of passwords in passwords1.txt', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of passwords in passwords2.txt 39000000\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "with open(\"passwords2.txt\") as infile:\n",
    "    for line in infile:\n",
    "        i = i+1\n",
    "print('Number of passwords in passwords2.txt', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sympy in c:\\users\\leona\\anaconda3\\lib\\site-packages (1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\leona\\anaconda3\\lib\\site-packages (from sympy) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sympy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose m(dimension of the future bit array) in respect of a 7% false positive rate that we will pose in the future bloom filter, so the module of the hash fucntions will the the first greater prime of 553490135."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553490137"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy as s\n",
    "m = s.nextprime(553490135)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313948731"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randrange(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create 4 hash functions, that we will later describe, the first thing we that I need 4 vectors with 20 components, all randomly generated in between 0 and m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomizr(m): \n",
    "    vec = []\n",
    "    for i in range(20):\n",
    "        vec.append(random.randrange(m))\n",
    "    return vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[548373287, 222232648, 393628080, 220566875, 315011190, 457014546, 401445075, 165870502, 544231662, 431020630, 189088991, 382246549, 207652822, 296995918, 282393338, 361281726, 379519948, 289192586, 422903918, 179727888] \n",
      " [510338572, 428859708, 127662473, 411969966, 268400108, 235368761, 316744780, 506406582, 545941917, 173198424, 519259740, 487278310, 165823038, 452155477, 51364823, 418169255, 277375778, 416769453, 246767791, 492198197] \n",
      " [372907205, 539742227, 324783969, 297544716, 334245771, 88148016, 531791743, 323977773, 386017264, 22958949, 341277333, 215029602, 313390962, 343400267, 91334501, 510518004, 437634524, 319955216, 323354422, 493771037] \n",
      " [429698059, 384014737, 257859287, 93358385, 410243180, 386311450, 514566367, 450082373, 480763392, 117581539, 403105809, 121520178, 313661122, 13845469, 325510496, 256279553, 371541715, 133092061, 56891456, 90041203]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "vector1 = randomizr(m)\n",
    "vector2 = randomizr(m)\n",
    "vector3 = randomizr(m)\n",
    "vector4 = randomizr(m)\n",
    "print(vector1,'\\n',vector2, '\\n', vector3, '\\n', vector4)\n",
    "print(vector1 == vector2 or vector1==vector3 or vector1==vector4 or vector2 == vector3 or vector3==vector4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the vectors are all different, to avoid changing them every time we run the file, we save the vectors with the values printed above. We did that to make explicit the uniform distribution to chooes those components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = [548373287, 222232648, 393628080, 220566875, 315011190, 457014546, 401445075, 165870502, 544231662, 431020630, 189088991, 382246549, 207652822, 296995918, 282393338, 361281726, 379519948, 289192586, 422903918, 179727888]\n",
    "vector2 = [510338572, 428859708, 127662473, 411969966, 268400108, 235368761, 316744780, 506406582, 545941917, 173198424, 519259740, 487278310, 165823038, 452155477, 51364823, 418169255, 277375778, 416769453, 246767791, 492198197]\n",
    "vector3 = [372907205, 539742227, 324783969, 297544716, 334245771, 88148016, 531791743, 323977773, 386017264, 22958949, 341277333, 215029602, 313390962, 343400267, 91334501, 510518004, 437634524, 319955216, 323354422, 493771037]\n",
    "vector4 = [429698059, 384014737, 257859287, 93358385, 410243180, 386311450, 514566367, 450082373, 480763392, 117581539, 403105809, 121520178, 313661122, 13845469, 325510496, 256279553, 371541715, 133092061, 56891456, 90041203]\n",
    "#done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def simple_dot(a, b):\n",
    "    dsum = 0.\n",
    "    for ((idx,), val) in np.ndenumerate(a):\n",
    "        dsum += int(val) * int(b[idx])\n",
    "    return int(dsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_dot([1,2], [4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the 4 hash fucntions, that will actually be the same but with different coefficients given by the vectors we just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hash1(x): \n",
    "    vec = []\n",
    "    for i in x:\n",
    "        vec.append(ord(i))\n",
    "    return (simple_dot(vec,vector1)%m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hash2(x): \n",
    "    vec = []\n",
    "    for i in x:\n",
    "        vec.append(ord(i))\n",
    "    return (simple_dot(vec,vector2)%m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hash3(x): \n",
    "    vec = []\n",
    "    for i in x:\n",
    "        vec.append(ord(i))\n",
    "    return (simple_dot(vec,vector3)%m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hash4(x): \n",
    "    vec = []\n",
    "    for i in x:\n",
    "        vec.append(ord(i))\n",
    "    return (simple_dot(vec,vector4)%m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have 4 Hash functions I need to build the bloom filter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def BloomFilter(passwords1, passwords2):\n",
    "    start = time.time()\n",
    "    filtr = [0]*553490137 #here m. the module\n",
    "    probably = 0\n",
    "    #first i put in my filter all the password from passwords1, signing with a 1 the components where there is something\n",
    "    with open(passwords1) as infile:\n",
    "        for line in infile:\n",
    "            item = line.replace('\\n','')\n",
    "            if filtr[Hash1(item)] == 0:\n",
    "                filtr[Hash1(item)] = 1\n",
    "            if filtr[Hash2(item)] == 0:\n",
    "                filtr[Hash2(item)] = 1\n",
    "            if filtr[Hash3(item)] == 0:\n",
    "                filtr[Hash3(item)] = 1\n",
    "            if filtr[Hash4(item)] == 0:\n",
    "                filtr[Hash4(item)] = 1\n",
    "    #now that every password from df passwords1 is inside, we have to put the new ones and count homw many are probably duplicates\n",
    "    with open(passwords2) as infile:\n",
    "        for line in infile:\n",
    "            item = line.replace('\\n','')\n",
    "            if filtr[Hash1(item)] == 1 and  filtr[Hash2(item)] == 1 and filtr[Hash2(item)] == 1 and filtr[Hash2(item)] == 1 :\n",
    "                probably = probably + 1\n",
    "    end = time.time()\n",
    "    #for the probability of false positive I build the model from the passwords1 size and i false positive rate i wanted, so it's 7%\n",
    "    print('Number of hash function used: ', 4)\n",
    "    print('Number of duplicates detected: ', probably)\n",
    "    print('Probability of false positives: ', 0.07)\n",
    "    print('Execution time: ', end-start)\n",
    "    return \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BloomFilter('passwords1.txt', 'passwords2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will modify a little the bloom filter to asnwer the bonus question about the exact number of false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def BloomFilter2(passwords1, passwords2):\n",
    "    start = time.time()\n",
    "    filtr = [0]*553490137 #here m. the module\n",
    "    false_pos = 0\n",
    "    #first i put in my filter all the password from passwords1, signing with a 1 the components where there is something\n",
    "    dic_hash1 = {}\n",
    "    with open(passwords1) as infile:\n",
    "        for line in infile:\n",
    "            item = line.replace('\\n','')\n",
    "            A = Hash1(item)\n",
    "            if filtr[Hash1(item)] == 0:\n",
    "                filtr[Hash1(item)] = 1\n",
    "                #we create a dictionary where i will access to verify if the password that has all 1 in the filter is really in the file.\n",
    "                dic_hash1[A] = [item]\n",
    "            else:\n",
    "                dic_hash1[A].append(item)\n",
    "            if filtr[Hash2(item)] == 0:\n",
    "                filtr[Hash2(item)] = 1\n",
    "            if filtr[Hash3(item)] == 0:\n",
    "                filtr[Hash3(item)] = 1\n",
    "            if filtr[Hash4(item)] == 0:\n",
    "                filtr[Hash4(item)] = 1\n",
    "    #now that every password from df passwords1 is inside, we have to put the new ones and count homw many are probably duplicates\n",
    "    with open(passwords2) as infile:\n",
    "        for line in infile:\n",
    "            item = line.replace('\\n','')\n",
    "            A = Hash1(item)\n",
    "            if filtr[A] == 1 and  filtr[Hash2(item)] == 1 and filtr[Hash2(item)] == 1 and filtr[Hash2(item)] == 1 :\n",
    "                if item not in filtr[A]:\n",
    "                    false_pos = false_pos + 1\n",
    "    end = time.time()\n",
    "    #for the probability of false positive I build the model from the passwords1 size and i false positive rate i wanted, so it's 7%\n",
    "    print('Number of hash function used: ', 4)\n",
    "    print('Number of false positives: ', false_pos)\n",
    "    print('Theoretical probability of false positives: ', 0.07)\n",
    "    print('Actual false positives probability', false_pos/float(39000000))\n",
    "    print('Execution time: ', end-start)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BloomFilter2('passwords1.txt', 'passwords2.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
